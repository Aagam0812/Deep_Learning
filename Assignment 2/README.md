# 🚀 LLM Explorer's Hub 🌌

Welcome to the **LLM Explorer's Hub**! This repository is your ultimate guide to diving deep into the world of Large Language Models (LLMs). From OpenAI's cutting-edge technology to exploring open-source models like Llama 2 in various formats, we cover it all! 🎉

## Colab
- **Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Aagam0812/Deep_Learning/blob/main/Assignment%202/CMPE258_Assigment2_LLM.ipynb)

## 📜 About

Our project is dedicated to exploring the vast universe of LLMs. We tackle everything from token exploration, utilizing OpenAI's API, to delving into open-source models such as Llama 2 in different formats (8 bit, 16 float points, TheBloke Quantized 7b, 13B, StableBeluga-7B, OpenOrca-Platypus2-13B). We're not just stopping there; we'll also guide you through Retrieval-Augmented Generation (RAG), fine-tuning techniques, and leveraging `llama_cpp` for CPU inference. 🌐

### 🌟 Features

- **Token Exploration**: Discover the significance of tokens in LLMs for better understanding and generation of text.
- **OpenAI Integration**: Learn how to leverage OpenAI's APIs for creating cutting-edge AI applications.
- **Open-Source Model Exploration**:
  - Explore Llama 2 models across various architectures and quantization methods.
  - Dive into models like TheBloke Quantized 7b, 13B, StableBeluga-7B, and OpenOrca-Platypus2-13B.
- **Retrieval-Augmented Generation (RAG)**: We've incorporated RAG to dynamically retrieve external documents and augment the model's responses. This technique significantly improves the accuracy and relevance of generated text by using real-time information from a variety of sources. It's particularly powerful in keeping the model's outputs up-to-date with the latest developments.
- **Fine-Tuning on Custom Datasets**: Our project also focuses on fine-tuning pre-trained models on specific datasets, such as "Abirate/english_quotes", to adapt models for specialized tasks. Fine-tuning allows the models to better understand and generate text related to specific themes or industries, enhancing their utility and applicability in niche areas.
- **Local Interpreter & Function Calling**: Experiment with building our own local interpreter for executing custom functions.
- **`llama_cpp` CPU Inference**: Utilize `llama_cpp` for integrating LLM capabilities into C++ applications, offering a new avenue for NLP projects.

## 📽️ Demo

For a detailed walkthrough of all this repository's features and functionalities, watch our demo video [here](https://drive.google.com/drive/folders/1-RRSZvc7yZLIhhSfTCj08vEMg2faX-cS?usp=sharing).

## 📚 Resources

- [OpenAI Documentation](https://openai.com/api/)
- [Llama GitHub Repository](https://github.com/EleutherAI)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)

Join us in exploring the limitless potential of Large Language Models! 🚀🌟
